{
  "name": "adversarial-testing-playground",
  "version": "1.0.0",
  "description": "A playground for testing adversarial attacks on ML models",
  "scripts": {
    "install:backend": "cd backend && pip install -r requirements.txt",
    "install:frontend": "cd frontend && npm install",
    "install:all": "npm run install:backend && npm run install:frontend",
    "dev:backend": "cd backend && python app.py",
    "dev:frontend": "cd frontend && npm run dev",
    "dev": "concurrently \"npm run dev:backend\" \"npm run dev:frontend\"",
    "build": "cd frontend && npm run build",
    "start": "cd frontend && npm start"
  },
  "devDependencies": {
    "concurrently": "^8.2.2"
  },
  "keywords": [
    "adversarial-attacks",
    "machine-learning",
    "flask",
    "nextjs",
    "react"
  ],
  "author": "",
  "license": "MIT"
}
